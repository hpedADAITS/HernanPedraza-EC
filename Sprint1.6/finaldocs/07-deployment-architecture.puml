@startuml Docker Deployment Architecture

!define CONTAINER_BG #C8E6C9
!define HOST_BG #BBDEFB
!define VOLUME_BG #FFF9C4
!define NETWORK_BG #FFE0B2

title Docker Deployment Architecture with Services and Volumes

package "Host Machine" <<folder>> #BBDEFB {
    
    package "LMStudio" {
        component "OpenAI-compatible\nAPI Server\n(localhost:1234)" #C8E6C9
        note on the right
          - IMPLEMENTER model
          - EXPANDER model
          - Token limit: 5000
        end note
    }
    
    package "Filesystem" {
        folder "/project-root/\n(user selects)" #FFF9C4
        folder "/media/" #FFF9C4
        folder "/diagrams/" #FFF9C4
    }
}

package "Docker Network\n(docker-compose)" <<folder>> #FFE0B2 {
    
    container "Backend Service" <<CONTAINER_BG>> {
        component "Node.js 18" {
            component "Express Server\n(port 3000)" 
            component "Controllers"
            component "Services"
            component "Analyzers"
            component "Utils"
        }
        
        note on the right of "Backend Service"
          Dockerfile:
          - FROM node:18-alpine
          - Install: plantuml, pandoc, git
          - CMD: node server.js
          
          Environment vars:
          - LMS_MODEL_PATH=/models/llama-3-8b-instruct
          - NODE_ENV=production
          - PORT=3000
        end note
    }
    
    container "Frontend Service" <<CONTAINER_BG>> {
        component "Nginx" {
            component "React App\n(compiled static)\n(port 8978)"
        }
        
        note on the right of "Frontend Service"
          Dockerfile:
          - FROM nginx:alpine
          - Build React app
          - Serve compiled dist/
          - PORT: 8978
        end note
    }
    
    "Express Server\n(port 3000)" ..> "localhost:1234" : HTTP POST\n(AI calls)
    "React App\n(compiled static)\n(port 8978)" ..> "Express Server\n(port 3000)" : HTTP requests\n(API endpoints)
}

package "Volumes & Bindings" <<folder>> #BBDEFB {
    
    volume "media-volume" <<VOLUME_BG>> {
        folder "Generated docs"
        folder "PDF files"
        folder "Execution logs"
    }
    
    volume "diagrams-volume" <<VOLUME_BG>> {
        folder "PlantUML source"
        folder "Rendered PNG files"
    }
    
    "Backend Service" --> "media-volume" : Read/Write\n(/app/media)
    "Backend Service" --> "diagrams-volume" : Read/Write\n(/app/diagrams)
}

note right of "Docker Network\n(docker-compose)"
  Service Dependencies:
  - Frontend depends_on: Backend
  - Backend depends_on: Nothing (external LMStudio)
  
  Service Communication:
  - Frontend → Backend: HTTP/REST
  - Backend → LMStudio: HTTP/OpenAI API
  
  Port Mappings:
  - 3000:3000 (Backend)
  - 8978:8978 (Frontend)
  - 1234:1234 (LMStudio - host only)
end note

package "Data Flow at Runtime" <<folder>> #F0F4C3 {
    
    participant "User Browser" as BROWSER
    participant "Docker Network" as DOCKER
    
    BROWSER -> "React App\n(compiled static)\n(port 8978)": http://localhost:8978
    "React App\n(compiled static)\n(port 8978)" -> "Express Server\n(port 3000)": POST /api/analyze
    "Express Server\n(port 3000)" -> "localhost:1234" : POST /v1/chat/completions
    "localhost:1234" --> "Express Server\n(port 3000)": AI response JSON
    "Express Server\n(port 3000)" -> "media-volume" : Write .md
    "Express Server\n(port 3000)" -> "diagrams-volume" : Write .puml, .png
    "Express Server\n(port 3000)" --> "React App\n(compiled static)\n(port 8978)": Response {markdown, pdfUrl, diagrams}
    "React App\n(compiled static)\n(port 8978)" --> BROWSER: Rendered results
}

note bottom
  Deployment Steps:
  
  1. Run: docker-compose up --build
     - Builds backend image
     - Builds frontend image
     - Starts both services
     - Mounts volumes
  
  2. Wait for startup:
     - Backend ready: can connect to 3000
     - Frontend ready: can access :8978
  
  3. Access application:
     - Open: http://localhost:8978
     - Connects to backend at :3000
     - Backend communicates with LMStudio at :1234
  
  4. Output artifacts:
     - Stored in mounted volumes (/media, /diagrams)
     - Persist after container shutdown
     - Accessible to both containers
end note

@enduml
